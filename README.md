# NLP_Tutorial-This repository has a tutorial and Roadmap the NLP.

![Uploading image.png…]()

**Natural Language Processing (NLP) is an artificial intelligence (AI) solution that aids computers in understanding, interpreting, and manipulating human language. Machine Translation, Conversational AI bots, Resume assessment, Fraud detection, and other applications of NLP are just a few examples. To construct AI-based systems, NLP uses the ideas of tokenization, entity recognition, word embeddings, topic modelling, and transfer learning.**

**The path below is what I followed during my CTS training(AI-ML), and it helped me tremendously in preparing for the ML interviews. It's also assisting me at work, where I work mostly on NLP and Deep Learning.**

# **Prerequisites to follow the Roadmap effectively**

* Basic Idea of Python programming language.
* Simple Idea of Machine and Deep Learning algorithms.

# **Libraries used while following the Roadmap**

> Natural Language Toolkit (NLTK)

> spaCy

> Core NLP

> Gensim (mainly for topic modeling)

> PyNLPI,etc.


# **Table content**

# **Pre-processing**(It includes levels 1 and 2 Pre-processing)

> Sentence cleaning

> Stop Words

> Regular Expression

> Tokenization

> N-grams (Unigram, Bigram, Trigram)

> Text Normalization

> Stemming

> Lemmatization

> Correction of Typos, etc.

# **Linguistics**

> Part-of-Speech Tags

> Constituency Parsing

> Dependency Parsing

> Syntactic Parsing

> Semantic Analysis

> Lexical Semantics

> Coreference Resolution

> Chunking

> Entity Extraction / Named Entity Recognition (NER)

> Named Entity Disambiguation / Entity Linking

> Knowledge Graphs

# **Word Embeddings**

**1. Frequency-based Word Embedding.**

> One Hot Encoding

> Bag of Words or CountVectorizer()

> TFIDF or TfidfVectorizer()

> Co-occurrence Matrix, Co-occurrence Vector

> HashingVectorizer

**2. Pretrained Word Embedding**

> Word2Vec (by Google) : (2 types) CBOW, Skip-Gram

> GloVe (by Stanford)

> fastText (by Facebook)

# **Topic Modeling**

> Latent Semantic Analysis (LSA)

> Probabilistic Latent Semantic Analysis (pLSA)

> Latent Dirichlet Allocation (LDA)

> lda2Vec

> Non-Negative Matrix Factorization (NMF)

# **NLP with Deep Learning**

> Machine Learning (Logistic Regression, SVM, Naïve Bayes)

> Artificial Neural Network

> Deep Neural Network

> Embedding Layer

> RNN/LSTM/GRU

> Bi-RNN/Bi-LSTM/Bi-GRU

> Pretrained Language Models: ELMo, ULMFiT

> Sequence-to-Sequence/Encoder-Decoder

> Transformers (attention mechanism)

> Encoder-only Transformers: BERT

> Decoder-only Transformers: GPT 

> Transfer Learning

# **Example Use cases**

> Sentiment Analysis

> Question Answering

> Language Translation

> Text/Intent Classification

> Text Summarization

> Text Similarity

> Text Clustering

> Text Generation

> Chatbots (DialogFlow, RASA, Self-made Bots)

**Refernce link:**

https://www.analyticsvidhya.com/blog/2022/01/roadmap-to-master-nlp-in-2022/

https://www.kaggle.com/code/kmldas/free-nlp-resources-courses/notebook

